{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a786c77c",
   "metadata": {},
   "source": [
    "# LangChain: Memory\n",
    "\n",
    "## Outline\n",
    "* ConversationBufferMemory\n",
    "* ConversationBufferWindowMemory\n",
    "* ConversationTokenBufferMemory\n",
    "* ConversationSummaryMemory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "431674c5",
   "metadata": {},
   "source": [
    "Conversation Memoryには、以下のような種類があります。\n",
    "\n",
    "* ConversationBufferMemory\n",
    "* ConversationBufferWindowMemory\n",
    "* ConversationTokenBufferMemory\n",
    "* ConversationSummaryMemory\n",
    "\n",
    "ConversationBufferMemoryは、しっかり見てはいませんが、他のメモリーの特徴から、全てのやりとりをそのまま記憶する機能だと思います。\n",
    "そのため、対話が長くなるトークン制限に引っかかると思います。（実際に引っかかるかを調べるのは面倒なのでやりません）\n",
    "\n",
    "ConversationBufferWindowMemoryは、直近k回分のやりとりを保持します。\n",
    "\n",
    "ConversationTokenBufferMemoryは、やりとりの回数ではなく、トークン数で記憶を管理します。max_tokensを決めると、対話履歴全体がその中に収まるようにしてくれます。\n",
    "長い文章を使った対話を行う場合や、対話履歴に他にもプロンプトを含めたい場合などに有効そうですね。\n",
    "\n",
    "ConversationSummaryMemoryは、max_tokensに収まるように対話履歴の要約を作成してくれます。\n",
    "直近の流れがわからないので、QAチャットボットなど、一問一答タイプの会話ならいいかもです。\n",
    "\n",
    "簡単にいくつかのConversation Memoryについて説明しました。\n",
    "詳しくは、ドキュメントを見てみてください。ナレッジグラフやベクトルストアを使うメモリーもあるようです。\n",
    "[Memory | 🦜️🔗 Langchain](https://python.langchain.com/docs/modules/memory/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1297dcd5",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de13e32e",
   "metadata": {},
   "source": [
    "まずは、一番シンプルなConversation Memoryです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a1f518f5",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "20ad6fe2",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "88bdf13d",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "db24677d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c293113",
   "metadata": {},
   "source": [
    "`verbose=True`とすることで、ConversationChainのプロンプトがわかりますね。\n",
    "```\n",
    "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "Human: *****\n",
    "AI: *****\n",
    "Human: *****\n",
    "AI: \n",
    "```\n",
    "\"以下の会話は、人間とAIの友好的な会話です。AIはおしゃべりで、コンテキストから具体的・詳細な内容を話します。AIは質問の答えを知らない場合、正直のそう言います。\"\n",
    "\n",
    "チャットボットで扱う場合は、他にも様々な指示をする必要がありそうですね。\n",
    "例えば、食や献立に関するアドバイスをするチャットボットを試そうとしたときは、いきなり適当なレシピを生成し、詳細な説明を出力してしまいました。\n",
    "そのため、「レシピ提案をしないでください。」という文言をプロンプトにに入れなければいけませんでした。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cc3ef937",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The answer to 1+1 is 2.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "acf3339a",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: The answer to 1+1 is 2.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Andrew, as you mentioned earlier.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2529400d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: The answer to 1+1 is 2.\n",
      "Human: What is my name?\n",
      "AI: Your name is Andrew, as you mentioned earlier.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5018cb0a",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, my name is Andrew\\nAI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\\nHuman: What is 1+1?\\nAI: The answer to 1+1 is 2.\\nHuman: What is my name?\\nAI: Your name is Andrew, as you mentioned earlier.\"}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b60ebdc",
   "metadata": {},
   "source": [
    "`memory.load_memory_variables({})`これはどういう機能なんでしょうか？よくわからないし、重要ではなさそうです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "14219b70",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a36e9905",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "61631b1f",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a2fdf9ec",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\"}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7ca79256",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "890a4497",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf98e9ff",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2dd9bbe5",
   "metadata": {},
   "source": [
    "次は、直近k回のやりとりを保存するConversation Memoryです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66eeccc3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "542ef1e5",
   "metadata": {},
   "source": [
    "`k=1`と設定すると、直近1回のやりとりのみ保存されていることが確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3ea6233e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dc4553fb",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6a788403",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4087bc87",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4faaa952",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bb20ddaa",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer to 1+1 is 2.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "489b2194",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't have access to that information. Could you please tell me your name?\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a1a975d",
   "metadata": {},
   "source": [
    "先ほどのConversationBufferMemoryと異なり、最初のやりとりで記憶した名前を覚えていません。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2931b92",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "895bc332",
   "metadata": {},
   "source": [
    "次に、トークン数によって保存するやりとりを決めるConversation Memoryです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9f6d063c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# !pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fb9020ed",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "43582ee6",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "284288e1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "478ae111",
   "metadata": {},
   "source": [
    "`max_token_limit=30`としているため、2つ目のAIからの応答以降の対話履歴を保存しています。\n",
    "`input`と`output`は常にセットなのかと思いましたが、そうではないようですね。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ff55d5d",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e5dc69d",
   "metadata": {},
   "source": [
    "最後は、トークン数に従って、対話履歴の要約を記憶するConversation Memoryです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "72dcf8b1",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6aef184d",
   "metadata": {},
   "source": [
    "わかりやすいようにChatGPTで日本語にしました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4a5b238f",
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"8時にあなたの製品チームとのミーティングがあります。\\\n",
    "パワーポイントのプレゼンテーションを準備する必要があります。\\\n",
    "午前9時から12時までは、LangChainプロジェクトに取り組む時間があります。\\\n",
    "LangChainは非常にパワフルなツールなので、作業はスムーズに進むでしょう。\\\n",
    "正午には、イタリアンレストランでお昼ご飯をお客様とともにとります。\\\n",
    "お客様は1時間以上かけて運転して会いに来る予定です。\\\n",
    "最新のAIについて理解するために、最新のLLMデモを見せるために、必ずノートパソコンを持ってきてください。\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"こんにちは。\"}, {\"output\": \"どうしたの？\"})\n",
    "memory.save_context({\"input\": \"なんでもないよ。ただぼーっとしてるだけ。\"},\n",
    "                    {\"output\": \"いいね。\"})\n",
    "memory.save_context({\"input\": \"今日の予定は何があった?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2e4ecabe",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human greets the AI in Japanese and the AI responds. The human asks about their schedule for the day and the AI provides a detailed list of tasks, including a meeting with the product team, working on the LangChain project, and having lunch with a client at an Italian restaurant. The AI reminds the human to bring their laptop to show the latest LLM demo to understand the latest AI.'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6728edba",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9a221b1d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human greets the AI in Japanese and the AI responds. The human asks about their schedule for the day and the AI provides a detailed list of tasks, including a meeting with the product team, working on the LangChain project, and having lunch with a client at an Italian restaurant. The AI reminds the human to bring their laptop to show the latest LLM demo to understand the latest AI.\n",
      "Human: どのようなデモが良いでしょうか？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'最新のLLMデモです。それは、自然言語処理に基づく言語モデルであり、言語の理解と生成に使用されます。デモでは、LLMがどのように機能するかを示し、その機能を実際に体験することができます。それは非常に興味深いです！'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"どのようなデモが良いでしょうか？\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02708c8b",
   "metadata": {},
   "source": [
    "これは会話風ですが、やっぱり一問一答向けです。「何時から何時にLangChainプロジェクトに取り組みますか？」のように、要約で落ちてしまった情報は復元できません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bb582617",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human greets the AI in Japanese and the AI responds. The human asks about their schedule for the day and the AI provides a detailed list of tasks, including a meeting with the product team, working on the LangChain project, and having lunch with a client at an Italian restaurant. The AI reminds the human to bring their laptop to show the latest LLM demo to understand the latest AI. The human asks about the demo and the AI explains that it is the latest LLM demo, which is a language model based on natural language processing used for language understanding and generation. The demo showcases how LLM works and allows for an interactive experience, which the AI finds very interesting.'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
