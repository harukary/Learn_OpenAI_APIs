{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a786c77c",
   "metadata": {},
   "source": [
    "# LangChain: Memory\n",
    "\n",
    "## Outline\n",
    "* ConversationBufferMemory\n",
    "* ConversationBufferWindowMemory\n",
    "* ConversationTokenBufferMemory\n",
    "* ConversationSummaryMemory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "431674c5",
   "metadata": {},
   "source": [
    "Conversation Memoryã«ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªç¨®é¡ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "* ConversationBufferMemory\n",
    "* ConversationBufferWindowMemory\n",
    "* ConversationTokenBufferMemory\n",
    "* ConversationSummaryMemory\n",
    "\n",
    "ConversationBufferMemoryã¯ã€ã—ã£ã‹ã‚Šè¦‹ã¦ã¯ã„ã¾ã›ã‚“ãŒã€ä»–ã®ãƒ¡ãƒ¢ãƒªãƒ¼ã®ç‰¹å¾´ã‹ã‚‰ã€å…¨ã¦ã®ã‚„ã‚Šã¨ã‚Šã‚’ãã®ã¾ã¾è¨˜æ†¶ã™ã‚‹æ©Ÿèƒ½ã ã¨æ€ã„ã¾ã™ã€‚\n",
    "ãã®ãŸã‚ã€å¯¾è©±ãŒé•·ããªã‚‹ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã«å¼•ã£ã‹ã‹ã‚‹ã¨æ€ã„ã¾ã™ã€‚ï¼ˆå®Ÿéš›ã«å¼•ã£ã‹ã‹ã‚‹ã‹ã‚’èª¿ã¹ã‚‹ã®ã¯é¢å€’ãªã®ã§ã‚„ã‚Šã¾ã›ã‚“ï¼‰\n",
    "\n",
    "ConversationBufferWindowMemoryã¯ã€ç›´è¿‘kå›åˆ†ã®ã‚„ã‚Šã¨ã‚Šã‚’ä¿æŒã—ã¾ã™ã€‚\n",
    "\n",
    "ConversationTokenBufferMemoryã¯ã€ã‚„ã‚Šã¨ã‚Šã®å›æ•°ã§ã¯ãªãã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã§è¨˜æ†¶ã‚’ç®¡ç†ã—ã¾ã™ã€‚max_tokensã‚’æ±ºã‚ã‚‹ã¨ã€å¯¾è©±å±¥æ­´å…¨ä½“ãŒãã®ä¸­ã«åã¾ã‚‹ã‚ˆã†ã«ã—ã¦ãã‚Œã¾ã™ã€‚\n",
    "é•·ã„æ–‡ç« ã‚’ä½¿ã£ãŸå¯¾è©±ã‚’è¡Œã†å ´åˆã‚„ã€å¯¾è©±å±¥æ­´ã«ä»–ã«ã‚‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å«ã‚ãŸã„å ´åˆãªã©ã«æœ‰åŠ¹ãã†ã§ã™ã­ã€‚\n",
    "\n",
    "ConversationSummaryMemoryã¯ã€max_tokensã«åã¾ã‚‹ã‚ˆã†ã«å¯¾è©±å±¥æ­´ã®è¦ç´„ã‚’ä½œæˆã—ã¦ãã‚Œã¾ã™ã€‚\n",
    "ç›´è¿‘ã®æµã‚ŒãŒã‚ã‹ã‚‰ãªã„ã®ã§ã€QAãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãªã©ã€ä¸€å•ä¸€ç­”ã‚¿ã‚¤ãƒ—ã®ä¼šè©±ãªã‚‰ã„ã„ã‹ã‚‚ã§ã™ã€‚\n",
    "\n",
    "ç°¡å˜ã«ã„ãã¤ã‹ã®Conversation Memoryã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã—ãŸã€‚\n",
    "è©³ã—ãã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¦‹ã¦ã¿ã¦ãã ã•ã„ã€‚ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã‚„ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä½¿ã†ãƒ¡ãƒ¢ãƒªãƒ¼ã‚‚ã‚ã‚‹ã‚ˆã†ã§ã™ã€‚\n",
    "[Memory | ğŸ¦œï¸ğŸ”— Langchain](https://python.langchain.com/docs/modules/memory/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1297dcd5",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de13e32e",
   "metadata": {},
   "source": [
    "ã¾ãšã¯ã€ä¸€ç•ªã‚·ãƒ³ãƒ—ãƒ«ãªConversation Memoryã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a1f518f5",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "20ad6fe2",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "88bdf13d",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "db24677d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c293113",
   "metadata": {},
   "source": [
    "`verbose=True`ã¨ã™ã‚‹ã“ã¨ã§ã€ConversationChainã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã‚ã‹ã‚Šã¾ã™ã­ã€‚\n",
    "```\n",
    "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "Human: *****\n",
    "AI: *****\n",
    "Human: *****\n",
    "AI: \n",
    "```\n",
    "\"ä»¥ä¸‹ã®ä¼šè©±ã¯ã€äººé–“ã¨AIã®å‹å¥½çš„ãªä¼šè©±ã§ã™ã€‚AIã¯ãŠã—ã‚ƒã¹ã‚Šã§ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å…·ä½“çš„ãƒ»è©³ç´°ãªå†…å®¹ã‚’è©±ã—ã¾ã™ã€‚AIã¯è³ªå•ã®ç­”ãˆã‚’çŸ¥ã‚‰ãªã„å ´åˆã€æ­£ç›´ã®ãã†è¨€ã„ã¾ã™ã€‚\"\n",
    "\n",
    "ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§æ‰±ã†å ´åˆã¯ã€ä»–ã«ã‚‚æ§˜ã€…ãªæŒ‡ç¤ºã‚’ã™ã‚‹å¿…è¦ãŒã‚ã‚Šãã†ã§ã™ã­ã€‚\n",
    "ä¾‹ãˆã°ã€é£Ÿã‚„çŒ®ç«‹ã«é–¢ã™ã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã™ã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’è©¦ãã†ã¨ã—ãŸã¨ãã¯ã€ã„ããªã‚Šé©å½“ãªãƒ¬ã‚·ãƒ”ã‚’ç”Ÿæˆã—ã€è©³ç´°ãªèª¬æ˜ã‚’å‡ºåŠ›ã—ã¦ã—ã¾ã„ã¾ã—ãŸã€‚\n",
    "ãã®ãŸã‚ã€ã€Œãƒ¬ã‚·ãƒ”ææ¡ˆã‚’ã—ãªã„ã§ãã ã•ã„ã€‚ã€ã¨ã„ã†æ–‡è¨€ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã«å…¥ã‚Œãªã‘ã‚Œã°ã„ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cc3ef937",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The answer to 1+1 is 2.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "acf3339a",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: The answer to 1+1 is 2.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Andrew, as you mentioned earlier.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2529400d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: The answer to 1+1 is 2.\n",
      "Human: What is my name?\n",
      "AI: Your name is Andrew, as you mentioned earlier.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5018cb0a",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, my name is Andrew\\nAI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\\nHuman: What is 1+1?\\nAI: The answer to 1+1 is 2.\\nHuman: What is my name?\\nAI: Your name is Andrew, as you mentioned earlier.\"}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b60ebdc",
   "metadata": {},
   "source": [
    "`memory.load_memory_variables({})`ã“ã‚Œã¯ã©ã†ã„ã†æ©Ÿèƒ½ãªã‚“ã§ã—ã‚‡ã†ã‹ï¼Ÿã‚ˆãã‚ã‹ã‚‰ãªã„ã—ã€é‡è¦ã§ã¯ãªã•ãã†ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "14219b70",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a36e9905",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "61631b1f",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a2fdf9ec",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\"}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7ca79256",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "890a4497",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf98e9ff",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2dd9bbe5",
   "metadata": {},
   "source": [
    "æ¬¡ã¯ã€ç›´è¿‘kå›ã®ã‚„ã‚Šã¨ã‚Šã‚’ä¿å­˜ã™ã‚‹Conversation Memoryã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66eeccc3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "542ef1e5",
   "metadata": {},
   "source": [
    "`k=1`ã¨è¨­å®šã™ã‚‹ã¨ã€ç›´è¿‘1å›ã®ã‚„ã‚Šã¨ã‚Šã®ã¿ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3ea6233e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dc4553fb",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6a788403",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4087bc87",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4faaa952",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bb20ddaa",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer to 1+1 is 2.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "489b2194",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't have access to that information. Could you please tell me your name?\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a1a975d",
   "metadata": {},
   "source": [
    "å…ˆã»ã©ã®ConversationBufferMemoryã¨ç•°ãªã‚Šã€æœ€åˆã®ã‚„ã‚Šã¨ã‚Šã§è¨˜æ†¶ã—ãŸåå‰ã‚’è¦šãˆã¦ã„ã¾ã›ã‚“ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2931b92",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "895bc332",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã«ã‚ˆã£ã¦ä¿å­˜ã™ã‚‹ã‚„ã‚Šã¨ã‚Šã‚’æ±ºã‚ã‚‹Conversation Memoryã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9f6d063c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# !pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fb9020ed",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "43582ee6",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "284288e1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "478ae111",
   "metadata": {},
   "source": [
    "`max_token_limit=30`ã¨ã—ã¦ã„ã‚‹ãŸã‚ã€2ã¤ç›®ã®AIã‹ã‚‰ã®å¿œç­”ä»¥é™ã®å¯¾è©±å±¥æ­´ã‚’ä¿å­˜ã—ã¦ã„ã¾ã™ã€‚\n",
    "`input`ã¨`output`ã¯å¸¸ã«ã‚»ãƒƒãƒˆãªã®ã‹ã¨æ€ã„ã¾ã—ãŸãŒã€ãã†ã§ã¯ãªã„ã‚ˆã†ã§ã™ã­ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ff55d5d",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e5dc69d",
   "metadata": {},
   "source": [
    "æœ€å¾Œã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã«å¾“ã£ã¦ã€å¯¾è©±å±¥æ­´ã®è¦ç´„ã‚’è¨˜æ†¶ã™ã‚‹Conversation Memoryã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "72dcf8b1",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6aef184d",
   "metadata": {},
   "source": [
    "ã‚ã‹ã‚Šã‚„ã™ã„ã‚ˆã†ã«ChatGPTã§æ—¥æœ¬èªã«ã—ã¾ã—ãŸã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4a5b238f",
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"8æ™‚ã«ã‚ãªãŸã®è£½å“ãƒãƒ¼ãƒ ã¨ã®ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãŒã‚ã‚Šã¾ã™ã€‚\\\n",
    "ãƒ‘ãƒ¯ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æº–å‚™ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\\\n",
    "åˆå‰9æ™‚ã‹ã‚‰12æ™‚ã¾ã§ã¯ã€LangChainãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å–ã‚Šçµ„ã‚€æ™‚é–“ãŒã‚ã‚Šã¾ã™ã€‚\\\n",
    "LangChainã¯éå¸¸ã«ãƒ‘ãƒ¯ãƒ•ãƒ«ãªãƒ„ãƒ¼ãƒ«ãªã®ã§ã€ä½œæ¥­ã¯ã‚¹ãƒ ãƒ¼ã‚ºã«é€²ã‚€ã§ã—ã‚‡ã†ã€‚\\\n",
    "æ­£åˆã«ã¯ã€ã‚¤ã‚¿ãƒªã‚¢ãƒ³ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã§ãŠæ˜¼ã”é£¯ã‚’ãŠå®¢æ§˜ã¨ã¨ã‚‚ã«ã¨ã‚Šã¾ã™ã€‚\\\n",
    "ãŠå®¢æ§˜ã¯1æ™‚é–“ä»¥ä¸Šã‹ã‘ã¦é‹è»¢ã—ã¦ä¼šã„ã«æ¥ã‚‹äºˆå®šã§ã™ã€‚\\\n",
    "æœ€æ–°ã®AIã«ã¤ã„ã¦ç†è§£ã™ã‚‹ãŸã‚ã«ã€æœ€æ–°ã®LLMãƒ‡ãƒ¢ã‚’è¦‹ã›ã‚‹ãŸã‚ã«ã€å¿…ãšãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã‚’æŒã£ã¦ãã¦ãã ã•ã„ã€‚\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"ã“ã‚“ã«ã¡ã¯ã€‚\"}, {\"output\": \"ã©ã†ã—ãŸã®ï¼Ÿ\"})\n",
    "memory.save_context({\"input\": \"ãªã‚“ã§ã‚‚ãªã„ã‚ˆã€‚ãŸã ã¼ãƒ¼ã£ã¨ã—ã¦ã‚‹ã ã‘ã€‚\"},\n",
    "                    {\"output\": \"ã„ã„ã­ã€‚\"})\n",
    "memory.save_context({\"input\": \"ä»Šæ—¥ã®äºˆå®šã¯ä½•ãŒã‚ã£ãŸ?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2e4ecabe",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human greets the AI in Japanese and the AI responds. The human asks about their schedule for the day and the AI provides a detailed list of tasks, including a meeting with the product team, working on the LangChain project, and having lunch with a client at an Italian restaurant. The AI reminds the human to bring their laptop to show the latest LLM demo to understand the latest AI.'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6728edba",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9a221b1d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human greets the AI in Japanese and the AI responds. The human asks about their schedule for the day and the AI provides a detailed list of tasks, including a meeting with the product team, working on the LangChain project, and having lunch with a client at an Italian restaurant. The AI reminds the human to bring their laptop to show the latest LLM demo to understand the latest AI.\n",
      "Human: ã©ã®ã‚ˆã†ãªãƒ‡ãƒ¢ãŒè‰¯ã„ã§ã—ã‚‡ã†ã‹ï¼Ÿ\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'æœ€æ–°ã®LLMãƒ‡ãƒ¢ã§ã™ã€‚ãã‚Œã¯ã€è‡ªç„¶è¨€èªå‡¦ç†ã«åŸºã¥ãè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€è¨€èªã®ç†è§£ã¨ç”Ÿæˆã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚ãƒ‡ãƒ¢ã§ã¯ã€LLMãŒã©ã®ã‚ˆã†ã«æ©Ÿèƒ½ã™ã‚‹ã‹ã‚’ç¤ºã—ã€ãã®æ©Ÿèƒ½ã‚’å®Ÿéš›ã«ä½“é¨“ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãã‚Œã¯éå¸¸ã«èˆˆå‘³æ·±ã„ã§ã™ï¼'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"ã©ã®ã‚ˆã†ãªãƒ‡ãƒ¢ãŒè‰¯ã„ã§ã—ã‚‡ã†ã‹ï¼Ÿ\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02708c8b",
   "metadata": {},
   "source": [
    "ã“ã‚Œã¯ä¼šè©±é¢¨ã§ã™ãŒã€ã‚„ã£ã±ã‚Šä¸€å•ä¸€ç­”å‘ã‘ã§ã™ã€‚ã€Œä½•æ™‚ã‹ã‚‰ä½•æ™‚ã«LangChainãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å–ã‚Šçµ„ã¿ã¾ã™ã‹ï¼Ÿã€ã®ã‚ˆã†ã«ã€è¦ç´„ã§è½ã¡ã¦ã—ã¾ã£ãŸæƒ…å ±ã¯å¾©å…ƒã§ãã¾ã›ã‚“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bb582617",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human greets the AI in Japanese and the AI responds. The human asks about their schedule for the day and the AI provides a detailed list of tasks, including a meeting with the product team, working on the LangChain project, and having lunch with a client at an Italian restaurant. The AI reminds the human to bring their laptop to show the latest LLM demo to understand the latest AI. The human asks about the demo and the AI explains that it is the latest LLM demo, which is a language model based on natural language processing used for language understanding and generation. The demo showcases how LLM works and allows for an interactive experience, which the AI finds very interesting.'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
