{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_stdout = sys.stdout\n",
    "sys.stdout = mystdout = StringIO()\n",
    "command = \"sorted([['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']], \\\n",
    "key=lambda x: (x[1], x[0]))\"\n",
    "exec(command)\n",
    "# exec(\"print(sorted([['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']], key=lambda x: (x[1], x[0])))\")\n",
    "sys.stdout = old_stdout\n",
    "output = mystdout.getvalue()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_python_agent(\n",
    "    llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    max_tokens=2000,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an agent designed to write and execute python code to answer questions.\n",
      "You have access to a python REPL, which you can use to execute python code.\n",
      "If you get an error, debug your code and try again.\n",
      "Only use the output of your code to answer the question. \n",
      "You might know the answer without running any code, but you should still run the code to get the answer.\n",
      "If it does not seem like you can write code to answer the question, just return \"I don't know\" as the answer.\n",
      "\n",
      "\n",
      "Python_REPL: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Python_REPL]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = agent.agent.llm_chain.prompt.template\n",
    "\n",
    "replaced_prompt = 'You can get the result only by using `print(...)`. \\\n",
    "The input python code should contains `print(...)`.'\n",
    "\n",
    "prompt_template = prompt_template.replace(\n",
    "    'If you want to see the output of a value, you should print it out with `print(...)`.',\n",
    "    replaced_prompt\n",
    ")\n",
    " \n",
    "agent.agent.llm_chain.prompt.template = prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an agent designed to write and execute python code to answer questions.\n",
      "You have access to a python REPL, which you can use to execute python code.\n",
      "If you get an error, debug your code and try again.\n",
      "Only use the output of your code to answer the question. \n",
      "You might know the answer without running any code, but you should still run the code to get the answer.\n",
      "If it does not seem like you can write code to answer the question, just return \"I don't know\" as the answer.\n",
      "\n",
      "\n",
      "Python_REPL: A Python shell. Use this to execute python commands. Input should be a valid python command. You can get the result only by using `print(...)`. The input python code should contains `print(...)`.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Python_REPL]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_list = [\n",
    "    [\"Harrison\", \"Chase\"], \n",
    "    [\"Lang\", \"Chain\"],\n",
    "    [\"Dolly\", \"Too\"],\n",
    "    [\"Elle\", \"Elem\"], \n",
    "    [\"Geoff\",\"Fusion\"], \n",
    "    [\"Trance\",\"Former\"],\n",
    "    [\"Jen\",\"Ayai\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI can use the `sorted()` function to sort the list of customers. I will need to provide a key function that specifies the sorting criteria.\n",
      "Action: Python_REPL\n",
      "Action Input: `customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]`\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI will use the `sorted()` function to sort the list of customers. I will provide a lambda function as the key function to specify the sorting criteria.\n",
      "Action: Python_REPL\n",
      "Action Input: `sorted(customers, key=lambda x: (x[1], x[0]))`\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse LLM output: `I now know the final answer.`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m agent\u001b[39m.\u001b[39;49mrun(\u001b[39mf\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\u001b[39mSort these customers by \u001b[39;49m\u001b[39m\\\u001b[39;49;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mlast name and then first name \u001b[39;49m\u001b[39m\\\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mand print the output: \u001b[39;49m\u001b[39m{\u001b[39;49;00mcustomer_list\u001b[39m}\u001b[39;49;00m\u001b[39m\"\"\"\u001b[39;49m) \n",
      "File \u001b[0;32m~/workspace/Learn_OpenAI_APIs/.venv/lib/python3.10/site-packages/langchain/chains/base.py:440\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    439\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[1;32m    441\u001b[0m         _output_key\n\u001b[1;32m    442\u001b[0m     ]\n\u001b[1;32m    444\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    445\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[1;32m    446\u001b[0m         _output_key\n\u001b[1;32m    447\u001b[0m     ]\n",
      "File \u001b[0;32m~/workspace/Learn_OpenAI_APIs/.venv/lib/python3.10/site-packages/langchain/chains/base.py:243\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 243\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    244\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    245\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    246\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    247\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/Learn_OpenAI_APIs/.venv/lib/python3.10/site-packages/langchain/chains/base.py:237\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    231\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    232\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    233\u001b[0m     inputs,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 237\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    238\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    239\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/workspace/Learn_OpenAI_APIs/.venv/lib/python3.10/site-packages/langchain/agents/agent.py:987\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m--> 987\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[1;32m    988\u001b[0m         name_to_tool_map,\n\u001b[1;32m    989\u001b[0m         color_mapping,\n\u001b[1;32m    990\u001b[0m         inputs,\n\u001b[1;32m    991\u001b[0m         intermediate_steps,\n\u001b[1;32m    992\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[1;32m    993\u001b[0m     )\n\u001b[1;32m    994\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m    995\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[1;32m    996\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[1;32m    997\u001b[0m         )\n",
      "File \u001b[0;32m~/workspace/Learn_OpenAI_APIs/.venv/lib/python3.10/site-packages/langchain/agents/agent.py:803\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    801\u001b[0m     raise_error \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39mif\u001b[39;00m raise_error:\n\u001b[0;32m--> 803\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    804\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(e)\n\u001b[1;32m    805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/workspace/Learn_OpenAI_APIs/.venv/lib/python3.10/site-packages/langchain/agents/agent.py:792\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Take a single step in the thought-action-observation loop.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \n\u001b[1;32m    788\u001b[0m \u001b[39mOverride this to take control of how the agent makes and acts on choices.\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    791\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m--> 792\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39;49mplan(\n\u001b[1;32m    793\u001b[0m         intermediate_steps,\n\u001b[1;32m    794\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    795\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs,\n\u001b[1;32m    796\u001b[0m     )\n\u001b[1;32m    797\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    798\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/workspace/Learn_OpenAI_APIs/.venv/lib/python3.10/site-packages/langchain/agents/agent.py:444\u001b[0m, in \u001b[0;36mAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m full_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    443\u001b[0m full_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfull_inputs)\n\u001b[0;32m--> 444\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_parser\u001b[39m.\u001b[39;49mparse(full_output)\n",
      "File \u001b[0;32m~/workspace/Learn_OpenAI_APIs/.venv/lib/python3.10/site-packages/langchain/agents/mrkl/output_parser.py:42\u001b[0m, in \u001b[0;36mMRKLOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m AgentFinish(\n\u001b[1;32m     38\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m: text\u001b[39m.\u001b[39msplit(FINAL_ANSWER_ACTION)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstrip()}, text\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m re\u001b[39m.\u001b[39msearch(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAction\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*:[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]*(.*?)\u001b[39m\u001b[39m\"\u001b[39m, text, re\u001b[39m.\u001b[39mDOTALL):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     43\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not parse LLM output: `\u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     44\u001b[0m         observation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid Format: Missing \u001b[39m\u001b[39m'\u001b[39m\u001b[39mAction:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m after \u001b[39m\u001b[39m'\u001b[39m\u001b[39mThought:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     45\u001b[0m         llm_output\u001b[39m=\u001b[39mtext,\n\u001b[1;32m     46\u001b[0m         send_to_llm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m     )\n\u001b[1;32m     48\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m re\u001b[39m.\u001b[39msearch(\n\u001b[1;32m     49\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]*Action\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*Input\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*:[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]*(.*)\u001b[39m\u001b[39m\"\u001b[39m, text, re\u001b[39m.\u001b[39mDOTALL\n\u001b[1;32m     50\u001b[0m ):\n\u001b[1;32m     51\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     52\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not parse LLM output: `\u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     53\u001b[0m         observation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid Format:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m         send_to_llm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m     )\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Could not parse LLM output: `I now know the final answer.`"
     ]
    }
   ],
   "source": [
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
